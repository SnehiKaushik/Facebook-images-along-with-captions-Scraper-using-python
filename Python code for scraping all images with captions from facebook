import requests  # to get image from the web
import shutil  # to save it locally
from facebook_scraper import get_posts
from docx import Document
from docx.shared import Inches

document = Document()


# add the name of the website without any blank spaces
for post in get_posts('sagelynaturals ', pages=10):

    a = post['image']

    if a == None:
        continue

    ## Set up the image URL and filename

    image_url = f"{a}"

    filename = image_url.split("/")[-1]

    # Open the url image, set stream to True, this will return the stream content.
    r = requests.get(image_url, stream=True)

    # Check if the image was retrieved successfully
    if r.status_code == 200:
        # Set decode_content value to True, otherwise the downloaded image file's size will be zero.
        r.raw.decode_content = True

        # Open a local file with wb ( write binary ) permission.
        with open(f"{post['post_id']}.jpg", 'wb') as f:
            shutil.copyfileobj(r.raw, f)

        print('Image sucessfully Downloaded: ', filename)
    else:
        print('Image Couldn\'t be retreived')
    p = document.add_paragraph(f"{post['text']}")
    document.add_picture(f"{post['post_id']}.jpg", width=Inches(1.25))

document.save('file_name.docx')
